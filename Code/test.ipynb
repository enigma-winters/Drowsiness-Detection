{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.0.1 (SDL 2.0.14, Python 3.7.3)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "from pygame import mixer\n",
    "import time\n",
    "from imutils.video import VideoStream\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "import argparse\n",
    "import imutils\n",
    "import pickle\n",
    "# import time\n",
    "# import cv2\n",
    "# import os\n",
    "import dlib\n",
    "from scipy.spatial import distance as dist\n",
    "x = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 22, 22, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 22, 22, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 20, 20, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 20, 20, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 18, 18, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 18, 18, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 18, 18, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 20736)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               2654336   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 258       \n",
      "=================================================================\n",
      "Total params: 2,682,658\n",
      "Trainable params: 2,682,658\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Eyes close and open\n",
    "model1 = load_model('trained_model_24_2.h5')\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading face detector\n",
      "loading the liveness detector\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Python\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:311: UserWarning: Trying to unpickle estimator LabelEncoder from version 0.20.2 when using version 0.19.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "#Liveness detector\n",
    "\n",
    "print(\"loading face detector\")\n",
    "protoPath =  'deploy.prototxt'\n",
    "\n",
    "#Loading the caffe model \n",
    "modelPath = 'res10_300x300_ssd_iter_140000.caffemodel'\n",
    "\n",
    "#reading data from the model.\n",
    "net = cv2.dnn.readNetFromCaffe(protoPath, modelPath)\n",
    "\n",
    "# loading the liveness detecting module that was trained in the training python script\n",
    "print(\"loading the liveness detector\")\n",
    "model2 = load_model('liveness.model')\n",
    "le = pickle.loads(open('le.pickle', \"rb\").read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#determining the facial points that are plotted by dlib\n",
    "FULL_POINTS = list(range(0, 68))  \n",
    "FACE_POINTS = list(range(17, 68))  \n",
    "   \n",
    "JAWLINE_POINTS = list(range(0, 17))  \n",
    "RIGHT_EYEBROW_POINTS = list(range(17, 22))  \n",
    "LEFT_EYEBROW_POINTS = list(range(22, 27))  \n",
    "NOSE_POINTS = list(range(27, 36))  \n",
    "RIGHT_EYE_POINTS = list(range(36, 42))  \n",
    "LEFT_EYE_POINTS = list(range(42, 48))  \n",
    "MOUTH_OUTLINE_POINTS = list(range(48, 61))  \n",
    "MOUTH_INNER_POINTS = list(range(61, 68))  \n",
    "   \n",
    "EYE_AR_THRESH = 0.30 \n",
    "EYE_AR_CONSEC_FRAMES = 2  \n",
    "\n",
    "#initializing the parameters\n",
    "COUNTER_LEFT = 0  \n",
    "TOTAL_LEFT = 0  \n",
    "   \n",
    "COUNTER_RIGHT = 0  \n",
    "TOTAL_RIGHT = 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining a function for calculating ear and then comparing with the confidence parametrs\n",
    "\n",
    "def eye_aspect_ratio(eye):\n",
    "    \n",
    "    A = dist.euclidean(eye[1], eye[5])  \n",
    "    B = dist.euclidean(eye[2], eye[4])\n",
    "    C = dist.euclidean(eye[0], eye[3])  \n",
    "    ear = (A + B) / (2.0 * C)  \n",
    "    return ear "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the predictor for predicting\n",
    "detector = dlib.get_frontal_face_detector()  \n",
    "\n",
    "#accessing the shape predictor\n",
    "predictor = dlib.shape_predictor('shape_predictor_68_face_landmarks.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "mixer.init()\n",
    "sound = mixer.Sound('TF050_2.wav')\n",
    "\n",
    "face = cv2.CascadeClassifier('haarcascade_frontalface_alt.xml')\n",
    "leye = cv2.CascadeClassifier('haarcascade_lefteye_2splits.xml')\n",
    "reye = cv2.CascadeClassifier('haarcascade_righteye_2splits.xml')\n",
    "\n",
    "\n",
    "\n",
    "lbl=['Close','Open']\n",
    "\n",
    "\n",
    "# path = os.getcwd()\n",
    "font = cv2.FONT_HERSHEY_COMPLEX_SMALL\n",
    "count=0\n",
    "score=0\n",
    "thicc=2\n",
    "rpred=[99]\n",
    "lpred=[99]\n",
    "alarm_threshold = 10\n",
    "# video_capture = cv2.VideoCapture(0)  \n",
    "fake_count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ARYAN\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Right eye winked\n",
      "Left eye winked\n",
      "Right eye winked\n",
      "Left eye winked\n",
      "Right eye winked\n",
      "Right eye winked\n",
      "Right eye winked\n",
      "Left eye winked\n",
      "Right eye winked\n",
      "Right eye winked\n",
      "Right eye winked\n",
      "Left eye winked\n",
      "Right eye winked\n",
      "Right eye winked\n",
      "Right eye winked\n",
      "Right eye winked\n",
      "Right eye winked\n",
      "Right eye winked\n",
      "Left eye winked\n",
      "Left eye winked\n",
      "Right eye winked\n",
      "Left eye winked\n",
      "Left eye winked\n",
      "Right eye winked\n",
      "Left eye winked\n",
      "Right eye winked\n",
      "Left eye winked\n",
      "Right eye winked\n",
      "Left eye winked\n",
      "Right eye winked\n",
      "Left eye winked\n",
      "Left eye winked\n",
      "Right eye winked\n",
      "Right eye winked\n",
      "Left eye winked\n",
      "Left eye winked\n",
      "Right eye winked\n",
      "Left eye winked\n",
      "Left eye winked\n",
      "Left eye winked\n",
      "Right eye winked\n",
      "Right eye winked\n",
      "Left eye winked\n",
      "Right eye winked\n",
      "Left eye winked\n",
      "Right eye winked\n"
     ]
    }
   ],
   "source": [
    "while(True):\n",
    "    ret, frame = cap.read()\n",
    "    fram1 = frame.copy()\n",
    "    \n",
    "    if ret:\n",
    "        \n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)  \n",
    "        rects = detector(gray, 0)\n",
    "        frame = imutils.resize(frame, width=600)\n",
    "        height,width = frame.shape[:2]\n",
    "        for rect in rects:\n",
    "            \n",
    "            x = rect.left()  \n",
    "            y = rect.top()  \n",
    "            x1 = rect.right()  \n",
    "            y1 = rect.bottom()\n",
    "            landmarks = np.matrix([[p.x, p.y] for p in predictor(frame, rect).parts()])  \n",
    "            left_eye = landmarks[LEFT_EYE_POINTS]  \n",
    "            right_eye = landmarks[RIGHT_EYE_POINTS]  \n",
    "            left_eye_hull = cv2.convexHull(left_eye)  \n",
    "            right_eye_hull = cv2.convexHull(right_eye)  \n",
    "            ear_left = eye_aspect_ratio(left_eye)  \n",
    "            ear_right = eye_aspect_ratio(right_eye)\n",
    "            \n",
    "#             faces = face.detectMultiScale(gray,minNeighbors=5,scaleFactor=1.1,minSize=(25,25))\n",
    "#             cv2.rectangle(frame, (0,height-50) , (200,height) , (0,0,0) , thickness=cv2.FILLED )\n",
    "#             for (x,y,w,h) in faces:\n",
    "#                 cv2.rectangle(frame, (x,y) , (x+w,y+h) , (100,100,100) , 1 )\n",
    "            \n",
    "#             cv2.rectangle(frame,(0,0),(width,height),(0,0,255),thicc)\n",
    "            \n",
    "            \n",
    "            #calculating blink wheneer the ear value drops down below the threshold\n",
    "            frame = imutils.resize(frame, width=600)\n",
    "            \n",
    "            if ear_left < EYE_AR_THRESH:\n",
    "                \n",
    "                COUNTER_LEFT += 1\n",
    "            \n",
    "            else:\n",
    "                \n",
    "                \n",
    "                if COUNTER_LEFT >= EYE_AR_CONSEC_FRAMES:\n",
    "                    \n",
    "                    \n",
    "                    TOTAL_LEFT += 1  \n",
    "                    print(\"Left eye winked\") \n",
    "                \n",
    "                    COUNTER_LEFT = 0\n",
    "            if ear_right < EYE_AR_THRESH:  \n",
    "                \n",
    "                \n",
    "                COUNTER_RIGHT += 1  \n",
    "\n",
    "            else:\n",
    "                \n",
    "                if COUNTER_RIGHT >= EYE_AR_CONSEC_FRAMES: \n",
    "                    \n",
    "                    \n",
    "                    TOTAL_RIGHT += 1  \n",
    "                    print(\"Right eye winked\")  \n",
    "                    COUNTER_RIGHT = 0\n",
    "\n",
    "\n",
    "            x = TOTAL_LEFT + TOTAL_RIGHT\n",
    "            \n",
    "            \n",
    "    (h, w) = frame.shape[:2]\n",
    "    temp = cv2.dnn.blobFromImage(cv2.resize(frame, (300, 300)), 1.0,\n",
    "\t\t(300, 300), (104.0, 177.0, 123.0))\n",
    "    net.setInput(temp)\n",
    "    detections = net.forward()\n",
    "    label = 0\n",
    "    p=0\n",
    "    sX=0\n",
    "    sY=0\n",
    "    eX = 0\n",
    "    eY = 0\n",
    "    for i in range(0, detections.shape[2]):\n",
    "\n",
    "\n",
    "        confidence = detections[0, 0, i, 2]\n",
    "\n",
    "          #staisfying the union need of veryfying through ROI and blink detection.  \n",
    "        if confidence > 0.5 and x>10:\n",
    "\n",
    "\n",
    "\n",
    "            #detect a bounding box\n",
    "        #take dimensions\n",
    "            box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])\n",
    "        #get the dimensions\n",
    "            (startX, startY, endX, endY) = box.astype(\"int\")\n",
    "\n",
    "\n",
    "            sX=startX = max(0, startX)\n",
    "            sY=startY = max(0, startY)\n",
    "            eX=endX = min(w, endX)\n",
    "            eY=endY = min(h, endY)\n",
    "\n",
    "        # extract the face ROI and then preproces it in the exact\n",
    "        # same manner as our training data\n",
    "            face = frame[startY:endY, startX:endX]\n",
    "            face = cv2.resize(face, (32, 32))\n",
    "            face = face.astype(\"float\") / 255.0\n",
    "            face = img_to_array(face)\n",
    "            face = np.expand_dims(face, axis=0)\n",
    "\n",
    "        #pass the model to determine the liveness\n",
    "            preds = model2.predict(face)[0]\n",
    "            j = np.argmax(preds)\n",
    "            label_1 = le.classes_[1-j] \n",
    "            \n",
    "            p = preds[j]\n",
    "            label = label_1.decode('UTF-8')\n",
    "            \n",
    "            \n",
    "    if(label == 'fake'):\n",
    "        fake_count += 1\n",
    "        if(fake_count >= 10):\n",
    "            try:\n",
    "                sound.play()\n",
    "            except:\n",
    "                pass\n",
    "    else:\n",
    "        fake_count = 0\n",
    "    \n",
    "    if(type(label) == int):\n",
    "        label = str(label)\n",
    "    label += (\" \" + str(p))\n",
    "    cv2.putText(frame,label,(250,height-10), font, 1,(255,255,255),1,cv2.LINE_AA)\n",
    "    cv2.putText(frame, label, (sX, sY - 10),\n",
    "\tcv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)\n",
    "    cv2.rectangle(frame, (sX, sY), (eX, eY),\n",
    "\t\t\t\t  (0, 0, 255), 2)\n",
    "\n",
    "    left_eye_1 = leye.detectMultiScale(gray)\n",
    "    right_eye_1 =  reye.detectMultiScale(gray)\n",
    "    r_eye,l_eye = 0,0\n",
    "\n",
    "    for (a,b,c,d) in right_eye_1:\n",
    "        r_eye=frame[b:b+d,a:a+c]\n",
    "        count=count+1\n",
    "        r_eye = cv2.cvtColor(r_eye,cv2.COLOR_BGR2GRAY)\n",
    "        r_eye = cv2.resize(r_eye,(24,24))                       #\n",
    "        r_eye= r_eye/255\n",
    "        r_eye=  r_eye.reshape(24,24,-1)                 #\n",
    "        r_eye = np.expand_dims(r_eye,axis=0)\n",
    "        rpred = model1.predict_classes(r_eye)\n",
    "        if(rpred[0]==1):\n",
    "            lbl='Open' \n",
    "        if(rpred[0]==0):\n",
    "            lbl='Closed'\n",
    "        break\n",
    "\n",
    "    for (a,b,c,d) in left_eye_1:\n",
    "        l_eye=frame[b:b+d,a:a+c]\n",
    "        count=count+1\n",
    "        l_eye = cv2.cvtColor(l_eye,cv2.COLOR_BGR2GRAY)  \n",
    "        l_eye = cv2.resize(l_eye,(24,24))                     #\n",
    "        l_eye= l_eye/255\n",
    "        l_eye=l_eye.reshape(24,24,-1)               #\n",
    "        l_eye = np.expand_dims(l_eye,axis=0)\n",
    "        lpred = model1.predict_classes(l_eye)\n",
    "        if(lpred[0]==1):\n",
    "            lbl='Open'   \n",
    "        if(lpred[0]==0):\n",
    "            lbl='Closed'\n",
    "        break\n",
    "\n",
    "    if(rpred[0]==0 and lpred[0]==0):\n",
    "        score=score+1\n",
    "        cv2.putText(frame,\"Closed\",(10,height-10), font, 1,(255,255,255),1,cv2.LINE_AA)\n",
    "    elif(rpred[0]==1 or lpred[0]==1):\n",
    "        score = 0\n",
    "        cv2.putText(frame,\"Open\",(10,height-10), font, 1,(255,255,255),1,cv2.LINE_AA)\n",
    "    else:\n",
    "        score=score-1\n",
    "        #score = 0\n",
    "        cv2.putText(frame,\"Open\",(10,height-10), font, 1,(255,255,255),1,cv2.LINE_AA)\n",
    "\n",
    "    if(score<0):\n",
    "        score=0   \n",
    "    cv2.putText(frame,'Score:'+str(score),(100,height-10), font, 1,(255,255,255),1,cv2.LINE_AA)\n",
    "    if(score>alarm_threshold):\n",
    "        try:\n",
    "            sound.play()\n",
    "\n",
    "        except:  # isplaying = False\n",
    "            pass\n",
    "        if(thicc<16):\n",
    "            thicc= thicc+2\n",
    "        else:\n",
    "            thicc=thicc-2\n",
    "            if(thicc<2):\n",
    "                thicc=2\n",
    "\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "    cv2.imshow('frame',frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
